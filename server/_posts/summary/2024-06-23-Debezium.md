---
layout: post  
title:  Spring Kafka
description:  
date: 2024-06-23 17:00 PM  
categories: summary
---

## Debezium

> Stream changes from your database.
>> Debezium is an open source distributed platform for change data capture. 
>> Start it up, point it at your databases, and your apps can start responding to all of 
>> the inserts, updates, and deletes that other apps commit to your databases. 
>> Debezium is durable and fast, so your apps can respond quickly and never miss an event, 
>> even when things go wrong.

Debezium 은 공식 문서에서 위와 같이 소개하고 있습니다.
간단하게 Database 에 변화(데이터 입력,변경 등)가 있을시 이를 감지하여 이벤트를 발생시킬수 있는 플랫폼이라 생각하시면 됩니다.

---

### CDC
`CDC` 란 `Change Data Capture` 의 약자로
데이터에 어떠한 변경이 발생하는지 추적하고 해당 변경 사항에 응답하는 서비스에 이벤트를 발생시키는 데이터 통합 패턴입니다.

일반적으로 Database 모니터링을 통해 다른 데이터베이스, 데이터 웨어하우스, 데이터 레이크, 이벤트 스트리밍 플랫폼에 변경사항을 전파하는데 사용합니다.

이중 이벤트 스트리밍 플랫폼 (Spring Boot + Kafka) 로 전달할 목적을 위해 사용하게 되었습니다.


### Debezium Connector
Debezium 은 Apache Kafka 위에 구축되어있으며 Kafka Connect 호환되는 여러 커넥터들이 있습니다.
각각의 DBMS 와 함께 작동하는 커넥터들은 변경 이벤트 레코드를 Kafka Topic 으로 스트리밍 하여 이를 기록하며,
소비 애플리케이션에서 이를 통해 레코드를 읽을 수 있습니다.

> Source Connector 종류
> - MySQL
> - MariaDb
> - MongoDb
> - PostgreSQL
> - Oracle
> - SQL Server
> - Db2
> - Cassandra
> - Vitess
> - Spanner
> - Informix

---

### MySQL Connector

현재 프로젝트에는 MySQL 을 사용하여 진행이 되고 있어 MySQL Connector 를 이용해 작업을 하였습니다.

MySQL에는 모든 작업을 커밋된 순서대로 기록하는 `Binlog` 가 있습니다. 
`Binlog` 에는 테이블 스키마의 변경 사항과 테이블의 데이터 변경 사항이 포함되고 이를 `replication`, `recovery`에 사용합니다.


#### MySQL 설정

Debezium Connector 에서 MySQL 의 `Binlog` 를 수집해 이를 통해 변경사항을 전달하게 되는데,
이를 위해 MySQL 의 설정 값을 확인해 봐야 합니다.

```console
// for MySQL 5.x
mysql> SELECT variable_value as "BINARY LOGGING STATUS (log-bin) ::"
FROM information_schema.global_variables WHERE variable_name='log_bin';
// for MySQL 8.x
mysql> SELECT variable_value as "BINARY LOGGING STATUS (log-bin) ::"
FROM performance_schema.global_variables WHERE variable_name='log_bin';

log_bin                     = mysql-bin
binlog_format               = ROW
binlog_row_image            = FULL
binlog_expire_logs_seconds  = 864000
```

위의 쿼리를 통해 나온 결과값이 이처럼 설정 되어 있어야 사용이 가능합니다.


#### Connector 설정

`Debezium Connector`를 생성하기위해 아래의 데이터를 
`curl --request POST localhost:8083/connectors -H 'Content-Type: application/json'` 로 전송

```json
{
  "name": "database-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",
    "database.hostname": "127.0.0.1",
    "database.port": "3306",
    "database.user": "user",
    "database.password": "password",
    "topic.prefix": "common-database",
    "database.server.id": "1",
    "database.include.list": "data,etc,etc2,etc3,common,app,event",
    "table.include.list": "data.order_table,etc3.delivery_delay,etc3.point,etc3.drop_price_notification",
    "include.schema.changes": "false",
//  1)  해당 부분이 전체 데이터를 가지고 오지 않도록 처리
    "snapshot.mode": "schema_only",


    "database.history.kafka.bootstrap.servers": "kafka1:29091,kafka2:29093,kafka3:29094",
//  2)  "database.serverTimezone"
    "database.connectionTimeZone": "Asia/Seoul",


    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "key.converter": "org.apache.kafka.connect.json.JsonConverter",


    "topic.creation.default.replication.factor" : 1,
    "topic.creation.default.partitions" : 1,
    "auto.create.topics.enable": "true",
    "schema.history.internal.kafka.bootstrap.servers": "kafka1:29091,kafka2:29093,kafka3:29094",
    "schema.history.internal.kafka.topic": "schemahistory.etc3"
  }
}
```

위와같이 옵션을 설정하여 커넥터를 생성하였습니다.
<br>
<br>
```json
{
  "snapshot.mode": "schema_only"
}
```
최초 커넥터를 생성할 당시 `snapshot` 이 생성되는데 기존 테이블의 모든 로우들을 topic에 적재하게 됩니다.
지금 필요한 부분은 앞으로의 Database 의 변경사항을 이벤트리스너에 전달하는 것이기 때문에 1) 옵션을 추가하여 처리해줬습니다.
만약 전체 데이터가 필요하다면 해당 부분을 지우면 됩니다.


```json
{
  //  2)  "database.serverTimezone"
  "database.connectionTimeZone": "Asia/Seoul"
}
```
옵션중 2) 옵션을 추가하지 않았었는데, 데이터 베이스의 타임존을 설정하지 않아 오류가 발생하여 서칭을 통해 추가 했었던 옵션입니다.
하지만 동일하게 오류가 발생하여 원인을 찾아보니 현재 Docker 에서 사용하고있는 Debezium 이미지의 버전과 맞지 않은 옵션이였고 (이전 버전 옵션), 
아래의 옵션을 추가하여 문제를 해결하였습니다. 

---

#### Connector 수정

이미 생성된 커넥터에 추가적으로 수집할 테이블을 추가하기 위해 수정해야하는 경우

`curl --request PUT localhost:8083/connectors/{database-connector 커넥터이름} -H 'Content-Type: application/json'`
해당 주소로 전체 옵션들을 전송하면 됩니다.

```json
{
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",
    "database.hostname": "127.0.0.1",
    "database.port": "3306",
    "database.user": "user",
    "database.password": "password",
    "topic.prefix": "common-database",
    "database.server.id": "1",
    "database.include.list": "data,etc,etc2,etc3,common,app,event",
    "table.include.list": "data.order_table,etc3.delivery_delay,etc3.point,etc3.drop_price_notification",
    "include.schema.changes": "false",

    "snapshot.mode": "schema_only",
    
    
    "database.history.kafka.bootstrap.servers": "kafka1:29091,kafka2:29093,kafka3:29094",
    "database.connectionTimeZone": "Asia/Seoul",
    
    
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "key.converter": "org.apache.kafka.connect.json.JsonConverter",
    
    
    "topic.creation.default.replication.factor" : 1,
    "topic.creation.default.partitions" : 1,
    "auto.create.topics.enable": "true",
    "schema.history.internal.kafka.bootstrap.servers": "kafka1:29091,kafka2:29093,kafka3:29094",
    "schema.history.internal.kafka.topic": "schemahistory.etc3"
}
```

---

위와같이 Debezium 을 추가하는 과정을 거쳤습니다.

프로젝트에 CDC를 추가한 이유는 기존 로직에 영향을 주지않고 해당 데이터가 변경된 이후 이벤트를 발생시키기 위해 였습니다.
기존에는 프로세스가 진행이되고 비교적 중요도가 적은 부분의 에러로 인하여 전체 프로세스가 롤백되는 현상들이 있었는데, 
이런부분의 중요도를 분리하고 별도로 처리하게 됨으로써 메인 프로세스의 안정을 추구할수 있을거라 생각했습니다.

DB 의 성능저하 부분도 걱정이 많이 되었던 부분이였는데,
Debezium 은 MySQL의 Slave replication 방식과 동일하게 동작하여 DB 성능에 큰 영향없이 빠르고 정확하게 추출하여 전달한다는 부분이 좋다고 보여,
이를 사용하게 되었습니다.